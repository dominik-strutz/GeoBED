{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BED data structures\n",
    "\n",
    "The test cases this structure should fullfill so far are\n",
    "1. simple one scalar measurment per design vector point (e.g: travel time source location)\n",
    "2. get combinations of arrival times for a number of design points  (e.g: travel time tomography)\n",
    "3. Deal with waveforms, meaning a single design point can give a measurment vector (e.g.: full waveform inversion)\n",
    "4. Deal with combined measurments of waveforms and scalar measurments\n",
    "5. \n",
    "\n",
    "the best is probably using a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dstrutz/sshfs/Libs/GeoBED/geobed/discrete/core.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "from  geobed.discrete.design2data_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up general parameters\n",
    "n_prior = 100\n",
    "\n",
    "n_design_points = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sequential_design(design_budget, design_meta_data, design2data):\n",
    "    budget = 0\n",
    "    optimal_design = []\n",
    "\n",
    "    while budget <= design_budget:\n",
    "        \n",
    "        EIG_optimal = -np.inf\n",
    "        # loop through all the designs \n",
    "        for name, meta_data in design_meta_data.items():\n",
    "            \n",
    "            # if the budget is not exceeded, add the design to the design set\n",
    "            if design_budget < budget + meta_data['cost']:\n",
    "                continue\n",
    "            temp_design = optimal_design + [name]\n",
    "\n",
    "            data = design2data(temp_design, design_meta_data, prior_samples=torch.ones((n_prior, 1)))\n",
    "\n",
    "            EIG = torch.sum(torch.sum(torch.log(data) * data, dim=-1), dim=0)\n",
    "                                                        \n",
    "            if EIG > EIG_optimal:\n",
    "                EIG_optimal = EIG\n",
    "                candidate = name\n",
    "        \n",
    "        if EIG_optimal == -np.inf:\n",
    "            break\n",
    "        \n",
    "        budget += design_meta_data[candidate]['cost']\n",
    "        optimal_design.append(candidate)            \n",
    "                \n",
    "    return optimal_design"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_names_case_1   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_1 = {\n",
    "    '1': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 0, 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 1, 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 2, 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 3, 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 4, 'cost': 1, 'x': 5, 'y': 6},\n",
    "}\n",
    "\n",
    "with h5py.File(\"data/case1_data.hdf5\", \"w\") as f:\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    data = f.create_dataset(\"data\", (n_prior, n_design_points, 1))        \n",
    "    data[:] = np.random.uniform(1, 2, (n_prior, n_design_points, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Constructing designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_1to1_design(temp_name_list, design_meta_data, prior_samples):\n",
    "    \n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "    \n",
    "    n_prior = prior_samples.shape[0]\n",
    "    data = torch.zeros((n_prior, len(temp_name_list), 1))    \n",
    "    \n",
    "    for i, design_meta in enumerate(design_meta_list):\n",
    "        with h5py.File(design_meta['file'], \"r\") as df:\n",
    "            data[:, i, :] = torch.from_numpy(df[design_meta['dataset']][:, design_meta['index'], :])\n",
    "\n",
    "    return data.flatten(start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '2', '5']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_1 = simple_sequential_design(3, design_meta_data_1, lookup_1to1_design)\n",
    "\n",
    "print(optimal_design_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_names_2 = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_2 = {\n",
    "    '1': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 4, 'y': 5},\n",
    "    }\n",
    "\n",
    "with h5py.File(\"case2_data.hdf5\", \"w\") as f:\n",
    "\n",
    "    np.random.seed(0)\n",
    "    data = f.create_dataset(\"data\", (n_prior, n_design_points * (n_design_points-1) // 2, 1))        \n",
    "    data[:] = np.random.uniform(1, 2, (n_prior, n_design_points * (n_design_points-1) // 2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_interstation_design(temp_name_list, design_meta_data, prior_samples):\n",
    "\n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "\n",
    "    if len(design_meta_list) == 1:\n",
    "        indices = []\n",
    "    else:\n",
    "        int_names = torch.tensor([int(name_i)-1 for name_i in temp_name_list])        \n",
    "        \n",
    "        indices = (torch.combinations(int_names)).tolist()    \n",
    "        indices = [list(sorted(i)) for i in indices]\n",
    "        \n",
    "        all_indices = zip(*torch.tril_indices(n_design_points, n_design_points, offset=-1).tolist())\n",
    "        all_indices = [list(sorted(i)) for i in all_indices]\n",
    "        \n",
    "        indices = [i for i, ind in enumerate(all_indices) if ind in indices]\n",
    "    \n",
    "    n_prior = prior_samples.shape[0]\n",
    "    data = torch.zeros((n_prior, len(indices), 1))    \n",
    "    \n",
    "    filename = design_meta_list[0]['file']\n",
    "    dataset_name = design_meta_list[0]['dataset']\n",
    "        \n",
    "    with h5py.File(filename, \"r\") as df:\n",
    "        data = torch.from_numpy(df[dataset_name][:, indices, :])\n",
    "        \n",
    "    return data.flatten(start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'data/case2_data.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m optimal_design_2 \u001b[39m=\u001b[39m simple_sequential_design(\u001b[39m3\u001b[39;49m, design_meta_data_2, lookup_interstation_design)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(optimal_design_2)\n",
      "\u001b[1;32m/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb Cell 14\u001b[0m in \u001b[0;36msimple_sequential_design\u001b[0;34m(design_budget, design_meta_data, design2data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m temp_design \u001b[39m=\u001b[39m optimal_design \u001b[39m+\u001b[39m [name]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m data \u001b[39m=\u001b[39m design2data(temp_design, design_meta_data, prior_samples\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mones((n_prior, \u001b[39m1\u001b[39;49m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m EIG \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mlog(data) \u001b[39m*\u001b[39m data, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m EIG \u001b[39m>\u001b[39m EIG_optimal:\n",
      "\u001b[1;32m/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb Cell 14\u001b[0m in \u001b[0;36mlookup_interstation_design\u001b[0;34m(temp_name_list, design_meta_data, prior_samples)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m filename \u001b[39m=\u001b[39m design_meta_list[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m dataset_name \u001b[39m=\u001b[39m design_meta_list[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m h5py\u001b[39m.\u001b[39;49mFile(filename, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m df:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(df[dataset_name][:, indices, :])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dstrutz/sshfs/Libs/GeoBED/notebooks/test_datastructure.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mflatten(start_dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/h5py/_hl/files.py:231\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m swmr \u001b[39mand\u001b[39;00m swmr_support:\n\u001b[1;32m    230\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, flags, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, h5f\u001b[39m.\u001b[39mACC_RDWR, fapl\u001b[39m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'data/case2_data.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "optimal_design_2 = simple_sequential_design(3, design_meta_data_2, lookup_interstation_design)\n",
    "\n",
    "print(optimal_design_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_waveform = 60\n",
    "\n",
    "design_names_3   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_3 = {\n",
    "    '1': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 0, 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 1, 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 2, 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 3, 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 4, 'cost': 1, 'x': 5, 'y': 6},\n",
    "}\n",
    "\n",
    "with h5py.File(\"case3_data.hdf5\", \"w\") as f:\n",
    "    data = f.create_dataset(\"data\", (n_prior, n_design_points, n_waveform))        \n",
    "    data[:] = np.random.uniform(1, 2, (n_prior, n_design_points, n_waveform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '4', '3']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_3 = simple_sequential_design(3, design_meta_data_3, lookup_1to1_design_variable_length)\n",
    "\n",
    "print(optimal_design_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_waveform_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "design_names_4   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_4 = {\n",
    "    '1': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 0, 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 1, 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 2, 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 3, 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 4, 'cost': 1, 'x': 5, 'y': 6},\n",
    "}\n",
    "\n",
    "with h5py.File(\"case4_data.hdf5\", \"w\") as f:\n",
    "    \n",
    "    variable_dt = h5py.vlen_dtype(np.dtype('float64'))\n",
    "    data = f.create_dataset('data', (n_prior, n_design_points,), dtype=variable_dt)\n",
    "    \n",
    "    for i_station, n_waveform in enumerate(n_waveform_list):\n",
    "        data[:, i_station] = np.random.uniform(1, 2, (n_prior, n_waveform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_1to1_design_variable_length(temp_name_list, design_meta_data, prior_samples):\n",
    "    \n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "                \n",
    "    data = []\n",
    "    \n",
    "    for i, design_meta in enumerate(design_meta_list):            \n",
    "        \n",
    "        with h5py.File(design_meta['file'], \"r\") as df:\n",
    "            i_data = np.stack(df[design_meta['dataset']][:, design_meta['index']])\n",
    "\n",
    "            data.append(i_data)\n",
    "                                      \n",
    "    return torch.from_numpy(np.concatenate(data, axis=-1))\n",
    "                                    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '4', '3']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_4 = simple_sequential_design(3, design_meta_data_4, lookup_1to1_design_variable_length)\n",
    "\n",
    "print(optimal_design_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_waveform_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "design_names   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data = {\n",
    "    '1': {'cost': 1, 'x': 1, 'y': 2, 'forward_function': torch.randint},\n",
    "    '2': {'cost': 1, 'x': 2, 'y': 3, 'forward_function': torch.randint},\n",
    "    '3': {'cost': 1, 'x': 3, 'y': 4, 'forward_function': torch.randint},\n",
    "    '4': {'cost': 1, 'x': 4, 'y': 5, 'forward_function': torch.randint},\n",
    "    '5': {'cost': 1, 'x': 5, 'y': 6, 'forward_function': torch.randint},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructor_1to1_design(temp_name_list, design_meta_data, prior_samples):\n",
    "    \n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "    \n",
    "    n_prior = prior_samples.shape[0]\n",
    "    \n",
    "    data = torch.zeros((n_prior, len(temp_name_list), 10))\n",
    "        \n",
    "    for i, d_meta in enumerate(design_meta_list):\n",
    "        data[:, i, :] = d_meta['forward_function'](1, 6, (n_prior, 10))\n",
    "\n",
    "    return data.flatten(start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '1', '4']\n"
     ]
    }
   ],
   "source": [
    "design_budget = 3\n",
    "\n",
    "# simple sequential design test case\n",
    "\n",
    "budget = 0\n",
    "optimal_design = []\n",
    "\n",
    "while budget <= design_budget:\n",
    "    \n",
    "    EIG_optimal = -np.inf\n",
    "    # loop through all the designs \n",
    "    for name, meta_data in design_meta_data.items():\n",
    "        \n",
    "        # if the budget is not exceeded, add the design to the design set\n",
    "        if design_budget < budget + meta_data['cost']:\n",
    "            continue\n",
    "        temp_design = optimal_design + [name]\n",
    "\n",
    "        data = constructor_1to1_design(temp_design, design_meta_data, prior_samples=torch.ones((n_prior, 1)))\n",
    "                    \n",
    "        EIG = torch.sum(torch.sum(torch.log(data) * data, dim=-1), dim=0)\n",
    "                                                    \n",
    "        if EIG > EIG_optimal:\n",
    "            EIG_optimal = EIG\n",
    "            candidate = name\n",
    "    \n",
    "    if EIG_optimal == -np.inf:\n",
    "        break\n",
    "    \n",
    "    budget += design_meta_data[candidate]['cost']\n",
    "    optimal_design.append(candidate)            \n",
    "            \n",
    "print(optimal_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FWI_ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008a53b85707028b5b437656de975d49d2753ba007c43b8804c7a863b7a0c241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
