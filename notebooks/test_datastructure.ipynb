{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test BED data structures\n",
    "\n",
    "The test cases this structure should fullfill so far are\n",
    "1. simple one scalar measurment per design vector point (e.g: travel time source location)\n",
    "2. get combinations of arrival times for a number of design points  (e.g: travel time tomography)\n",
    "3. Deal with waveforms, meaning a single design point can give a measurment vector (e.g.: full waveform inversion)\n",
    "4. Deal with combined measurments of waveforms and scalar measurments\n",
    "5. \n",
    "\n",
    "the best is probably using a user defined function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "from  geobed.design2data_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up general parameters\n",
    "n_prior = 100\n",
    "\n",
    "n_design_points = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_sequential_design(design_budget, design_meta_data, design2data):\n",
    "    budget = 0\n",
    "    optimal_design = []\n",
    "\n",
    "    while budget <= design_budget:\n",
    "        \n",
    "        EIG_optimal = -np.inf\n",
    "        # loop through all the designs \n",
    "        for name, meta_data in design_meta_data.items():\n",
    "            \n",
    "            # if the budget is not exceeded, add the design to the design set\n",
    "            if design_budget < budget + meta_data['cost']:\n",
    "                continue\n",
    "            temp_design = optimal_design + [name]\n",
    "\n",
    "            data = design2data(temp_design, design_meta_data, prior_samples=torch.ones((n_prior, 1)))\n",
    "\n",
    "            EIG = torch.sum(torch.sum(torch.log(data) * data, dim=-1), dim=0)\n",
    "                                                        \n",
    "            if EIG > EIG_optimal:\n",
    "                EIG_optimal = EIG\n",
    "                candidate = name\n",
    "        \n",
    "        if EIG_optimal == -np.inf:\n",
    "            break\n",
    "        \n",
    "        budget += design_meta_data[candidate]['cost']\n",
    "        optimal_design.append(candidate)            \n",
    "                \n",
    "    return optimal_design"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_names_case_1   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_1 = {\n",
    "    '1': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 0, 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 1, 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 2, 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 3, 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case1_data.hdf5', 'dataset': 'data', 'index': 4, 'cost': 1, 'x': 5, 'y': 6},\n",
    "}\n",
    "\n",
    "with h5py.File(\"case1_data.hdf5\", \"w\") as f:\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    data = f.create_dataset(\"data\", (n_prior, n_design_points, 1))        \n",
    "    data[:] = np.random.uniform(1, 2, (n_prior, n_design_points, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Constructing designs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_1to1_design(temp_name_list, design_meta_data, prior_samples):\n",
    "    \n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "    \n",
    "    n_prior = prior_samples.shape[0]\n",
    "    data = torch.zeros((n_prior, len(temp_name_list), 1))    \n",
    "    \n",
    "    for i, design_meta in enumerate(design_meta_list):\n",
    "        with h5py.File(design_meta['file'], \"r\") as df:\n",
    "            data[:, i, :] = torch.from_numpy(df[design_meta['dataset']][:, design_meta['index'], :])\n",
    "\n",
    "    return data.flatten(start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '2', '5']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_1 = simple_sequential_design(3, design_meta_data_1, lookup_1to1_design)\n",
    "\n",
    "print(optimal_design_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_names_2 = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_2 = {\n",
    "    '1': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case2_data.hdf5', 'dataset': 'data', 'cost': 1, 'x': 4, 'y': 5},\n",
    "    }\n",
    "\n",
    "with h5py.File(\"case2_data.hdf5\", \"w\") as f:\n",
    "\n",
    "    np.random.seed(0)\n",
    "    data = f.create_dataset(\"data\", (n_prior, n_design_points * (n_design_points-1) // 2, 1))        \n",
    "    data[:] = np.random.uniform(1, 2, (n_prior, n_design_points * (n_design_points-1) // 2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_interstation_design(temp_name_list, design_meta_data, prior_samples):\n",
    "\n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "\n",
    "    if len(design_meta_list) == 1:\n",
    "        indices = []\n",
    "    else:\n",
    "        int_names = torch.tensor([int(name_i)-1 for name_i in temp_name_list])        \n",
    "        \n",
    "        indices = (torch.combinations(int_names)).tolist()    \n",
    "        indices = [list(sorted(i)) for i in indices]\n",
    "        \n",
    "        all_indices = zip(*torch.tril_indices(n_design_points, n_design_points, offset=-1).tolist())\n",
    "        all_indices = [list(sorted(i)) for i in all_indices]\n",
    "        \n",
    "        indices = [i for i, ind in enumerate(all_indices) if ind in indices]\n",
    "    \n",
    "    n_prior = prior_samples.shape[0]\n",
    "    data = torch.zeros((n_prior, len(indices), 1))    \n",
    "    \n",
    "    filename = design_meta_list[0]['file']\n",
    "    dataset_name = design_meta_list[0]['dataset']\n",
    "        \n",
    "    with h5py.File(filename, \"r\") as df:\n",
    "        data = torch.from_numpy(df[dataset_name][:, indices, :])\n",
    "        \n",
    "    return data.flatten(start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '5', '3']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_2 = simple_sequential_design(3, design_meta_data_2, lookup_interstation_design)\n",
    "\n",
    "print(optimal_design_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_waveform = 60\n",
    "\n",
    "design_names_3   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_3 = {\n",
    "    '1': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 0, 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 1, 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 2, 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 3, 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case3_data.hdf5', 'dataset': 'data', 'index': 4, 'cost': 1, 'x': 5, 'y': 6},\n",
    "}\n",
    "\n",
    "with h5py.File(\"case3_data.hdf5\", \"w\") as f:\n",
    "    data = f.create_dataset(\"data\", (n_prior, n_design_points, n_waveform))        \n",
    "    data[:] = np.random.uniform(1, 2, (n_prior, n_design_points, n_waveform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '4', '3']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_3 = simple_sequential_design(3, design_meta_data_3, lookup_1to1_design_variable_length)\n",
    "\n",
    "print(optimal_design_3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_waveform_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "design_names_4   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data_4 = {\n",
    "    '1': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 0, 'cost': 1, 'x': 1, 'y': 2},\n",
    "    '2': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 1, 'cost': 1, 'x': 2, 'y': 3},\n",
    "    '3': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 2, 'cost': 1, 'x': 3, 'y': 4},\n",
    "    '4': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 3, 'cost': 1, 'x': 4, 'y': 5},\n",
    "    '5': {'file': 'data/case4_data.hdf5', 'dataset': 'data', 'index': 4, 'cost': 1, 'x': 5, 'y': 6},\n",
    "}\n",
    "\n",
    "with h5py.File(\"case4_data.hdf5\", \"w\") as f:\n",
    "    \n",
    "    variable_dt = h5py.vlen_dtype(np.dtype('float64'))\n",
    "    data = f.create_dataset('data', (n_prior, n_design_points,), dtype=variable_dt)\n",
    "    \n",
    "    for i_station, n_waveform in enumerate(n_waveform_list):\n",
    "        data[:, i_station] = np.random.uniform(1, 2, (n_prior, n_waveform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_1to1_design_variable_length(temp_name_list, design_meta_data, prior_samples):\n",
    "    \n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "                \n",
    "    data = []\n",
    "    \n",
    "    for i, design_meta in enumerate(design_meta_list):            \n",
    "        \n",
    "        with h5py.File(design_meta['file'], \"r\") as df:\n",
    "            i_data = np.stack(df[design_meta['dataset']][:, design_meta['index']])\n",
    "\n",
    "            data.append(i_data)\n",
    "                                      \n",
    "    return torch.from_numpy(np.concatenate(data, axis=-1))\n",
    "                                    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '4', '3']\n"
     ]
    }
   ],
   "source": [
    "optimal_design_4 = simple_sequential_design(3, design_meta_data_4, lookup_1to1_design_variable_length)\n",
    "\n",
    "print(optimal_design_4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Case (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_waveform_list = [10, 20, 30, 40, 50]\n",
    "\n",
    "design_names   = [str(i) for i in range(n_design_points)]\n",
    "\n",
    "design_meta_data = {\n",
    "    '1': {'cost': 1, 'x': 1, 'y': 2, 'forward_function': torch.randint},\n",
    "    '2': {'cost': 1, 'x': 2, 'y': 3, 'forward_function': torch.randint},\n",
    "    '3': {'cost': 1, 'x': 3, 'y': 4, 'forward_function': torch.randint},\n",
    "    '4': {'cost': 1, 'x': 4, 'y': 5, 'forward_function': torch.randint},\n",
    "    '5': {'cost': 1, 'x': 5, 'y': 6, 'forward_function': torch.randint},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructor_1to1_design(temp_name_list, design_meta_data, prior_samples):\n",
    "    \n",
    "    temp_name_list = list(set(temp_name_list)) # remove duplicates \n",
    "    design_meta_list = [design_meta_data[n] for n in temp_name_list]\n",
    "    \n",
    "    n_prior = prior_samples.shape[0]\n",
    "    \n",
    "    data = torch.zeros((n_prior, len(temp_name_list), 10))\n",
    "        \n",
    "    for i, d_meta in enumerate(design_meta_list):\n",
    "        data[:, i, :] = d_meta['forward_function'](1, 6, (n_prior, 10))\n",
    "\n",
    "    return data.flatten(start_dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '1', '4']\n"
     ]
    }
   ],
   "source": [
    "design_budget = 3\n",
    "\n",
    "# simple sequential design test case\n",
    "\n",
    "budget = 0\n",
    "optimal_design = []\n",
    "\n",
    "while budget <= design_budget:\n",
    "    \n",
    "    EIG_optimal = -np.inf\n",
    "    # loop through all the designs \n",
    "    for name, meta_data in design_meta_data.items():\n",
    "        \n",
    "        # if the budget is not exceeded, add the design to the design set\n",
    "        if design_budget < budget + meta_data['cost']:\n",
    "            continue\n",
    "        temp_design = optimal_design + [name]\n",
    "\n",
    "        data = constructor_1to1_design(temp_design, design_meta_data, prior_samples=torch.ones((n_prior, 1)))\n",
    "                    \n",
    "        EIG = torch.sum(torch.sum(torch.log(data) * data, dim=-1), dim=0)\n",
    "                                                    \n",
    "        if EIG > EIG_optimal:\n",
    "            EIG_optimal = EIG\n",
    "            candidate = name\n",
    "    \n",
    "    if EIG_optimal == -np.inf:\n",
    "        break\n",
    "    \n",
    "    budget += design_meta_data[candidate]['cost']\n",
    "    optimal_design.append(candidate)            \n",
    "            \n",
    "print(optimal_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FWI_ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "008a53b85707028b5b437656de975d49d2753ba007c43b8804c7a863b7a0c241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
